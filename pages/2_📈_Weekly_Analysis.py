import streamlit as st
import pandas as pd
from datetime import date
import os

st.set_page_config(page_title="ğŸ“ˆ Weekly Analysis", layout="wide")

st.title("ğŸ“ˆ Weekly Analysis")

@st.cache_data
def load_data():
    # Streamlit ì•± ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ
    hoka_sub = os.path.join("data", "hoka_subreddit.csv")
    other_subs = os.path.join("data", "hoka_posts.csv")
    # hoka_sub = r"C:\Users\rootn\OneDrive\Desktop\Reddit\data\hoka_subreddit.csv"
    # other_subs = r"C:\Users\rootn\OneDrive\Desktop\Reddit\data\hoka_posts.csv"

    df1 = pd.read_csv(hoka_sub)
    df2 = pd.read_csv(other_subs)

    df1["time"] = pd.to_datetime(df1["time"], errors='coerce')
    df2["time"] = pd.to_datetime(df2["time"], errors='coerce')

    df1 = df1.dropna(subset=["time"])
    df2 = df2.dropna(subset=["time"])

    df1["week"] = df1["time"].dt.to_period("W-SAT").apply(lambda r: r.start_time)
    df2["week"] = df2["time"].dt.to_period("W-SAT").apply(lambda r: r.start_time)

    return df1, df2

hoka_df, subreddit_df = load_data()

tab1, tab2 = st.tabs(["ğŸ“ˆ r/Hoka ì£¼ê°„ í™œë™", "ğŸ“ˆ ê¸°íƒ€ ì„œë¸Œë ˆë”§ ì£¼ê°„ í™œë™"])

with tab1:
    st.markdown("### ğŸ“ˆ r/Hoka ì£¼ê°„ ë¶„ì„")

    min_date = hoka_df["time"].min().date()
    max_date = hoka_df["time"].max().date()
    default_end = min(date.today(), max_date)

    start_date, end_date = st.date_input(
        "ğŸ“… ë‚ ì§œ ì„ íƒ",
        (min_date, default_end),
        min_value=min_date,
        max_value=max_date,
        key="hoka_date"
    )

    df_filtered = hoka_df[
        (hoka_df["time"].dt.date >= start_date) &
        (hoka_df["time"].dt.date <= end_date)
    ]

    weekly = df_filtered.groupby("week").agg({
        "score": "sum",
        "num_comments": "sum"
    })
    weekly["post_count"] = df_filtered.groupby("week").size()
    weekly.index = pd.to_datetime(weekly.index)

    st.subheader("ğŸ“Š Total Score and Comments Count")
    st.line_chart(weekly[["score", "num_comments"]])

    st.subheader("ğŸ“ Posts Count")
    st.line_chart(weekly["post_count"])

with tab2:
    st.markdown("### ğŸ“ˆ ê¸°íƒ€ ì„œë¸Œë ˆë”§ì˜ Hoka ê´€ë ¨ ì£¼ê°„ ë¶„ì„")

    subreddits = sorted(subreddit_df["subreddit"].dropna().unique())
    use_filter = st.checkbox("ğŸ” ì„œë¸Œë ˆë”§ í•„í„°ë§")

    if use_filter:
        selected_subs = st.multiselect("ì„œë¸Œë ˆë”§ ì„ íƒ", subreddits, default=subreddits[:3])
    else:
        selected_subs = subreddits  # âœ… ì „ì²´ ì„œë¸Œë ˆë”§ ëŒ€ìƒ

    min_date = subreddit_df["time"].min().date()
    max_date = subreddit_df["time"].max().date()
    default_end = min(date.today(), max_date)

    start_date2, end_date2 = st.date_input(
        "ğŸ“… ë‚ ì§œ ì„ íƒ",
        (date(2025, 1, 25), default_end),
        min_value=min_date,
        max_value=max_date,
        key="subreddit_date"
    )

    filtered_df = subreddit_df[
        (subreddit_df["subreddit"].isin(selected_subs)) &
        (subreddit_df["time"].dt.date >= start_date2) &
        (subreddit_df["time"].dt.date <= end_date2)
    ]

    weekly2 = filtered_df.groupby("week").agg({
        "score": "sum",
        "num_comments": "sum"
    })
    weekly2["post_count"] = filtered_df.groupby("week").size()
    weekly2.index = pd.to_datetime(weekly2.index)

    st.subheader("ğŸ“Š Total score and Comments count")
    st.line_chart(weekly2[["score", "num_comments"]])

    st.subheader("ğŸ“ Posts count")
    st.line_chart(weekly2["post_count"])